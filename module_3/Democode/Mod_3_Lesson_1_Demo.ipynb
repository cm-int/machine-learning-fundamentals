{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTaoGFZh0Wa-"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cm-int/machine-learning-fundamentals/blob/main/module_3/Democode/Mod_3_Lesson_1_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q48Z00umUdo6"
      },
      "source": [
        "#Comparing Samples\n",
        "\n",
        "In this demonstration, you’ll see how to compare samples against a population. You'll see how to examine the entropy and KL divergence of the distributions. Then you'll perform comparisons using measures of central tendency and dispersion and see how to locate samples that are suspect. \n",
        "\n",
        "This demonstration uses the Bank Marketing dataset.\n",
        "\n",
        "This dataset is public available for research. The details are described in [Moro et al., 2011] S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology.\n",
        "In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimarães, Portugal, October, 2011. EUROSIS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OGr7_gIM_qZ"
      },
      "source": [
        "# Examine the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMvNb7MU0H_m"
      },
      "outputs": [],
      "source": [
        "# Upload the marketingdata.csv file\n",
        "\n",
        "!wget 'https://raw.githubusercontent.com/cm-int/machine-learning-fundamentals/main/module_3/Democode/marketingdata.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iMEi04Q2OT2"
      },
      "outputs": [],
      "source": [
        "# Read the data from the CSV file\n",
        "# This is our population from which we will draw samples\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "marketing = pd.read_csv(\"marketingdata.csv\", sep=';')\n",
        "print(marketing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isZWQgT8Tng7"
      },
      "outputs": [],
      "source": [
        "# Focus on the 'job' feature\n",
        "\n",
        "job = marketing['job']\n",
        "print(job)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hX-c-scToYk"
      },
      "outputs": [],
      "source": [
        "# Create a dataframe with a zero count for each job (this will be used later to handle missing probability values)\n",
        "\n",
        "zero_dataframe = pd.DataFrame(data=[np.zeros(12)], columns=np.sort(job.unique()))\n",
        "print(zero_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnyUjStr74vW"
      },
      "outputs": [],
      "source": [
        "# Draw a histogram to display the distribution of jobs from the population\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "f = sns.histplot(data=np.sort(job), kde=True)\n",
        "f.set_xlabel('Job', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.set_ylabel(\"Count\", fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.tick_params(labelsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Capture the probabilities for each job\n",
        "pop_probs = [i.get_height()/len(job) for i in f.containers[0]]\n",
        "pop_dataframe = pd.DataFrame(data=[pop_probs], columns=[t.get_text() for t in f.get_xticklabels()]).fillna(0).iloc[0]\n",
        "print(pop_dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUtUYkNgJr2h"
      },
      "source": [
        "**Questions:**\n",
        "\n",
        "What is the mode of this dataset?\n",
        "\n",
        "*Answer: blue-collar*\n",
        "\n",
        "What is the mean of this dataset?\n",
        "\n",
        "*Answer: Calculating the mean of a categorical non-ordinal dataset is not meaningful.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW6WlAcN8frf"
      },
      "outputs": [],
      "source": [
        "# Show counts and probabilities for each job category\n",
        "\n",
        "total = len(job)\n",
        "print(f'Total number of datapoints: {total}\\n')\n",
        "\n",
        "for j in np.sort(job.unique()):\n",
        "  n = len(job[job == j])\n",
        "  print(f'{j}: {n}, P(x={j}): {n/total}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tm6hl4LxxuOP"
      },
      "outputs": [],
      "source": [
        "# Retrieve some random samples from the population\n",
        "\n",
        "from numpy import random\n",
        "\n",
        "sample1 = np.random.choice(job, size=1000)\n",
        "sample2 = np.random.choice(job, size=100)\n",
        "sample3 = np.random.choice(job, size=10)\n",
        "\n",
        "sortedjob = np.sort(job)\n",
        "\n",
        "#idx = abs(np.random.laplace(777, 7777, 7777)).astype(int) % len(job)\n",
        "idx = abs(np.random.normal(loc=15000, scale=5700, size=21000)).astype(int) % len(job)\n",
        "sample4 = [sortedjob[j] for j in idx]\n",
        "\n",
        "idx = abs(np.random.exponential(7000, 1000)).astype(int) % len(job)\n",
        "sample5 = [sortedjob[j] for j in idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_pYkO695VRI"
      },
      "outputs": [],
      "source": [
        "# Draw a histogram to display the distribution of jobs in sample1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "f = sns.histplot(data=np.sort(sample1), kde=True)\n",
        "f.set_xlabel('Job', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.set_ylabel(\"Count\", fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.tick_params(labelsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Capture the probabilities for each job in this sample\n",
        "sample1_probs = [i.get_height()/len(sample1) for i in f.containers[0]]\n",
        "sample1_dataframe = pd.DataFrame(data=[sample1_probs], columns=[t.get_text() for t in f.get_xticklabels()])\n",
        "\n",
        "# Replace any NAs resulting from the merge with 10e-99 - a minutely small probability\n",
        "# If you use zero, relative entropy compared to a finite value is infinity\n",
        "sample1_dataframe = sample1_dataframe.merge(zero_dataframe, how = 'outer').fillna(10e-99).iloc[0] \n",
        "print(sample1_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Tq_fmj19YAy"
      },
      "outputs": [],
      "source": [
        "# Draw a histogram to display the distribution of jobs in sample2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "f = sns.histplot(data=np.sort(sample2), kde=True)\n",
        "f.set_xlabel('Job', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.set_ylabel(\"Count\", fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.tick_params(labelsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Capture the probabilities for each job in this sample\n",
        "sample2_probs = [i.get_height()/len(sample2) for i in f.containers[0]]\n",
        "sample2_dataframe = pd.DataFrame(data=[sample2_probs], columns=[t.get_text() for t in f.get_xticklabels()])\n",
        "sample2_dataframe = sample2_dataframe.merge(zero_dataframe, how = 'outer').fillna(10e-99).iloc[0]\n",
        "print(sample2_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN74SjsMBG0q"
      },
      "outputs": [],
      "source": [
        "# Draw a histogram to display the distribution of jobs in sample3\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "f = sns.histplot(data=np.sort(sample3), kde=True)\n",
        "f.set_xlabel('Job', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.set_ylabel(\"Count\", fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.tick_params(labelsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Capture the probabilities for each job in this sample\n",
        "sample3_probs = [i.get_height()/len(sample3) for i in f.containers[0]]\n",
        "sample3_dataframe = pd.DataFrame(data=[sample3_probs], columns=[t.get_text() for t in f.get_xticklabels()])\n",
        "sample3_dataframe = sample3_dataframe.merge(zero_dataframe, how = 'outer').fillna(10e-99).iloc[0]\n",
        "print(sample3_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpS7Q6pyBoq5"
      },
      "outputs": [],
      "source": [
        "# Draw a histogram to display the distribution of jobs in sample4\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "f = sns.histplot(data=np.sort(sample4), kde=True)\n",
        "f.set_xlabel('Job', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.set_ylabel(\"Count\", fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.tick_params(labelsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Capture the probabilities for each job in this sample\n",
        "sample4_probs = [i.get_height()/len(sample4) for i in f.containers[0]]\n",
        "sample4_dataframe = pd.DataFrame(data=[sample4_probs], columns=[t.get_text() for t in f.get_xticklabels()])\n",
        "sample4_dataframe = sample4_dataframe.merge(zero_dataframe, how = 'outer').fillna(10e-99).iloc[0]\n",
        "print(sample4_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yKugy5NDECB"
      },
      "outputs": [],
      "source": [
        "# Draw a histogram to display the distribution of jobs in sample5\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "f = sns.histplot(data=np.sort(sample5), kde=True)\n",
        "f.set_xlabel('Job', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.set_ylabel(\"Count\", fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.tick_params(labelsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Capture the probabilities for each job in this sample\n",
        "sample5_probs = [i.get_height()/len(sample5) for i in f.containers[0]]\n",
        "sample5_dataframe = pd.DataFrame(data=[sample5_probs], columns=[t.get_text() for t in f.get_xticklabels()])\n",
        "sample5_dataframe = sample5_dataframe.merge(zero_dataframe, how = 'outer').fillna(10e-99).iloc[0]\n",
        "print(sample5_dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FDnXUh9Msce"
      },
      "source": [
        "# How different are the samples from the population?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3YpbFiVxBoR"
      },
      "outputs": [],
      "source": [
        "# Calculate the entropy of each sample\n",
        "\n",
        "from scipy.stats import entropy\n",
        "\n",
        "e_pop = entropy(pop_probs)\n",
        "e_sample1 = entropy(sample1_probs)\n",
        "e_sample2 = entropy(sample2_probs)\n",
        "e_sample3 = entropy(sample3_probs)\n",
        "e_sample4 = entropy(sample4_probs)\n",
        "e_sample5 = entropy(sample5_probs)\n",
        "\n",
        "print(f'Entropies.\\nPopulation:{e_pop}\\nSample1:{e_sample1}\\nSample2:{e_sample2}\\nSample3:{e_sample3}\\nSample4:{e_sample4}\\nSample5:{e_sample5}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGKSg_QZxqOo"
      },
      "outputs": [],
      "source": [
        "# What is the relative entropy of sample1 to the population?\n",
        "# The difference should be small because sample1 is a true random sample of 'reasonable' size compared to the population\n",
        "\n",
        "import scipy.special as sp\n",
        "import math\n",
        "\n",
        "print(f'{sample1_dataframe}\\n')\n",
        "print(f'Relative entropy is {sum(sp.rel_entr(pop_dataframe, sample1_dataframe))} nats')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drkTTG5QHK75"
      },
      "outputs": [],
      "source": [
        "# How about sample2?\n",
        "# The difference starting to become more noticable due to the sample size\n",
        "\n",
        "print(f'{sample2_dataframe}\\n')\n",
        "print(f'Relative entropy is {sum(sp.rel_entr(pop_dataframe, sample2_dataframe))} nats')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmqQD0Ebgys9"
      },
      "outputs": [],
      "source": [
        "# Sample3\n",
        "# Entropy is rising quickly, again due to sample size\n",
        "\n",
        "print(f'{sample3_dataframe}\\n')\n",
        "print(f'Relative entropy is {sum(sp.rel_entr(pop_dataframe, sample3_dataframe))} nats')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HdgQZaki6k0"
      },
      "outputs": [],
      "source": [
        "# Sample4\n",
        "# Entropy is caused by the sample data coming from a skewed distribution\n",
        "\n",
        "print(f'{sample4_dataframe}\\n')\n",
        "print(f'Relative entropy is {sum(sp.rel_entr(pop_dataframe, sample4_dataframe))} nats')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GC_arzBEjIkb"
      },
      "outputs": [],
      "source": [
        "# Sample5\n",
        "# Entropy is smaller despite the sample data coming from a skewed distribution\n",
        "\n",
        "print(f'{sample5_dataframe}\\n')\n",
        "print(f'Relative entropy is {sum(sp.rel_entr(pop_dataframe, sample5_dataframe))} nats')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOt6OpiYkyQQ"
      },
      "source": [
        "**Conclusion:**\n",
        "\n",
        "Entropy and KL-divergence can give you an indication of whether your sampling is too small and/or skewed. The closer the entropy of a sample is to that of the population, and the smaller the KL-divergence, the better the sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPmfHffzMzfE"
      },
      "source": [
        "# Compare Distributions using Measures of Central Tendency and Dispersion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLtAMzyyx29e"
      },
      "outputs": [],
      "source": [
        "# This time, focus on the Balance feature. This is the average yearly balance, in euros\n",
        "\n",
        "balance = marketing['balance']\n",
        "print(balance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6Nf52DNMqq5"
      },
      "outputs": [],
      "source": [
        "# Examine the min, max, mean, median, standard deviation, and kurtosis of the Balance feature to get an idea of its level of dispersion\n",
        "# The high standard deviation and kurtosis values indicate a long tail\n",
        "\n",
        "print(f'Minimum is: {balance.min()}\\n')\n",
        "print(f'Maximum is: {balance.max()}\\n')\n",
        "print(f'Mean is: {balance.mean()}\\n')\n",
        "print(f'Median is: {balance.median()}\\n')\n",
        "print(f'Standard Deviation is: {balance.std()}\\n')\n",
        "print(f'Kurtosis is: {balance.kurtosis()}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h8DNtbdO2bT"
      },
      "outputs": [],
      "source": [
        "# Plot a histogram to help understand the shape of the population\n",
        "# This is not a Gaussian distribution\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "f = sns.histplot(data=np.sort(balance), kde=True)\n",
        "f.set_xlabel('Balance', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.set_ylabel('Count', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.tick_params(labelsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FO7oBOjrQ4cv"
      },
      "outputs": [],
      "source": [
        "# Zoom in on the data: Use bigger buckets spanning ranges of values\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "counts, _, bars = plt.hist(balance, bins=41)\n",
        "\n",
        "for bar in bars:\n",
        "   x = (bar._x0 + bar._x1)/2 - 2000\n",
        "   y = bar._y1 + 500\n",
        "   plt.text(x, y, format(bar._y1, '.0f'), c='red')\n",
        "plt.xlabel('Balance', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "plt.ylabel('Count', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "plt.xticks(np.arange(-10000, 110000, 3000), rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa0TN8DaYqCJ"
      },
      "outputs": [],
      "source": [
        "# Select 100 samples from this population\n",
        "\n",
        "samples=np.empty((100, 500))\n",
        "for i in range(0, 100):\n",
        "  samples[i] = np.random.choice(balance, size=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLY9A-MgZDwQ"
      },
      "outputs": [],
      "source": [
        "# Plot two of the samples selected at random and show the means, medians, and standard deviations\n",
        "\n",
        "sample1 = np.random.choice(range(0, 100))\n",
        "sample2 = np.random.choice(range(0, 100))\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(40, 10))\n",
        "counts, _, bars = ax1.hist(samples[sample1], bins=41)\n",
        "for bar in bars:\n",
        "   x = (bar._x0 + bar._x1)/2 - 0.5\n",
        "   y = bar._y1 + 1.5\n",
        "   ax1.text(x-300, y+2, format(bar._y1, '.0f'), c='red', fontdict={'fontsize': 15})\n",
        "ax1.set_xlabel('Balance', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 28})\n",
        "ax1.set_ylabel('Count', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 28})\n",
        "\n",
        "counts, _, bars = ax2.hist(samples[sample2], bins=41)\n",
        "for bar in bars:\n",
        "   x = (bar._x0 + bar._x1)/2 - 0.5\n",
        "   y = bar._y1 + 1.5\n",
        "   ax2.text(x-300, y+2, format(bar._y1, '.0f'), c='red', fontdict={'fontsize': 15})\n",
        "ax2.set_xlabel('Balance', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 28})\n",
        "ax2.set_ylabel('Count', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 28})\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(f'Means: {np.mean(samples[sample1])}, {np.mean(samples[sample2])}\\n')\n",
        "print(f'Medians: {np.median(samples[sample1])}, {np.median(samples[sample2])}\\n')\n",
        "print(f'Standard Deviations: {np.std(samples[sample1])}, {np.std(samples[sample2])}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4krOQmEfxAK"
      },
      "outputs": [],
      "source": [
        "# Calculate the mean for every sample\n",
        "\n",
        "means = [np.mean(samples[i]) for i in range(0, 100)]\n",
        "print(means)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_BCWjtKhs6l"
      },
      "outputs": [],
      "source": [
        "# Plot the means and notice the distribution. \n",
        "# According to the Central Limit Theorem the distribution should be close to Gaussian although the original distribution is not\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "f = sns.histplot(means, kde=True)\n",
        "f.set_xlabel('Means', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.set_ylabel('Count', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.tick_params(labelsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOw9QvxQiWO4"
      },
      "outputs": [],
      "source": [
        "# Compare the mean of the population against the mean of the means\n",
        "\n",
        "print(f'Population mean: {np.mean(balance)}\\nMean of sample means: {np.mean(means)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx9oCoFkmLy_"
      },
      "outputs": [],
      "source": [
        "# Calculate the t-statistic and p-value of the mean of the means against the population\n",
        "# Any value for the p-value below 0.05 indicates that the difference in means is statistically significant (but see later)\n",
        "\n",
        "from scipy import stats as st\n",
        "\n",
        "print(st.ttest_1samp(means, np.mean(balance)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JqN5jNEj609"
      },
      "outputs": [],
      "source": [
        "# Now take 1000 samples from the population\n",
        "\n",
        "samples=np.empty((1000, 500))\n",
        "for i in range(0, 1000):\n",
        "  samples[i] = np.random.choice(balance, size=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cML2ACZAkPYK"
      },
      "outputs": [],
      "source": [
        "# Calculate the mean for every sample\n",
        "\n",
        "means = [np.mean(samples[i]) for i in range(0, 1000)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Mb5huJYkHcA"
      },
      "outputs": [],
      "source": [
        "# Plot the means. \n",
        "# The distribution should be even closer to Gaussian\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "f = sns.histplot(means, kde=True)\n",
        "f.set_xlabel('Means', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.set_ylabel('Count', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 20})\n",
        "f.tick_params(labelsize=12)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1gLA4TOno-4"
      },
      "outputs": [],
      "source": [
        "# Compare the mean of the means to the mean of the population\n",
        "# Why might the t-statistic be smaller despite the bigger sample? (hint: Consider the standard error)\n",
        "\n",
        "print(f'Population mean: {np.mean(balance)}\\nMean of sample means: {np.mean(means)}')\n",
        "print(st.ttest_1samp(means, np.mean(balance)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLwptR1xuo7Q"
      },
      "outputs": [],
      "source": [
        "# Analyze the sample means by computing the Z-score relative to the normalized population\n",
        "# How many standard deviations is the mean of the sample means from the mean of the population? What does this signify?\n",
        "\n",
        "sigma = np.std(balance)\n",
        "mu = np.mean(balance)\n",
        "x_bar = np.mean(samples)\n",
        "\n",
        "z_score = (x_bar-mu)/sigma\n",
        "print(z_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl0NdSb756Mm"
      },
      "outputs": [],
      "source": [
        "# Find the p-value for this Z-score\n",
        "# Note: Multiply by two because this is a two-tailed test\n",
        "\n",
        "print(f'p-value is {st.norm.sf(abs(z_score)) * 2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_1AqWygTbSy"
      },
      "outputs": [],
      "source": [
        "# 'Spike' a few of the samples to give us some questionable data\n",
        "\n",
        "samples[0] = -999999.99\n",
        "samples[100] = -9999999.9\n",
        "samples[500] = -9999999.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQYXYoZl4nQY"
      },
      "outputs": [],
      "source": [
        "# Find the Z-scores and p-values for the mean of each sample\n",
        "\n",
        "scores=np.empty((2, 1000))\n",
        "for i in range(0, 1000):\n",
        "  scores[0, i] = (np.mean(samples[i])-mu)/sigma\n",
        "  scores[1, i] = st.norm.sf(abs(scores[0, i])) * 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emn09qw7IJBy"
      },
      "outputs": [],
      "source": [
        "# Find any samples with a p-value that is too distant from the population mean\n",
        "# These are dodgy samples that should be discarded!\n",
        "# (The threshold is set much higher than the usual value of 0.05 for statistical significance)\n",
        "\n",
        "threshold = 0.75\n",
        "print(np.where(scores[1, :] < threshold))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifvVUr3AlZwv"
      },
      "source": [
        "# Conclusion:\n",
        "\n",
        "The more samples you take from a population, the closer the aggregated mean of these samples is to the mean of the population.\n",
        "\n",
        "Beware of using the t-test to compare samples with a size bigger than 30 due to the standard error. Calculate the Z-score instead."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
