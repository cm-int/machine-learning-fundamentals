{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Y5ikrgMVlsHP56v0fW50h-amVeEeQHyf","timestamp":1670772660615}],"authorship_tag":"ABX9TyNzFvV3ZlQDa4RM888BzeP+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<a href=\"https://colab.research.google.com/github/cm-int/machine-learning-fundamentals/blob/main/module_3/Labs/Lab3_2_Handling_Imbalanced_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"],"metadata":{"id":"GnXIeSXSesog"}},{"cell_type":"markdown","source":["# Lab 3.2: Handling Imbalanced Data\n","\n","In this lab, you'll perform the following tasks:\n","\n","1. Build a Random Forest model to classify an imbalanced dataset without making any modifications.\n","1. Examine the results and evaluate the performance using appropriate metrics.\n","1. Use sampling to balance the dataset and rebuild and retest the model.\n","1. Use bagging with sampling and rebuild and retest the model.\n","1. Use boosting with sampling and rebuild and restest the model.\n","1. Calibrate the model and restest it.\n","1. Build another model using the original imbalanced dataset, then calibrate and evaluate the model.\n","1. Combine models using a VotingClassifier and evaluate the results.\n","\n","## Scenario\n","\n","Diabetes is among the most prevalent chronic diseases in the United States, impacting millions of Americans each year and exerting a significant financial burden on the economy.\n","\n","Complications like heart disease, vision loss, lower-limb amputation, and kidney disease are associated with chronically high levels of sugar remaining in the bloodstream for those with diabetes. While there is no cure for diabetes, strategies like losing weight, eating healthily, being active, and receiving medical treatments can mitigate the harms of this disease in many patients. Early diagnosis can lead to lifestyle changes and more effective treatment, making predictive models for diabetes risk important tools for public and public health officials.\n","\n","The Behavioral Risk Factor Surveillance System (BRFSS) is a system of health-related telephone surveys that collect state data about U.S. residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services. Established in 1984 with 15 states, BRFSS now collects data in all 50 states as well as the District of Columbia and three U.S. territories. BRFSS completes more than 400,000 adult interviews each year, making it the largest continuously conducted health survey system in the world.\n","\n","The dataset contains the following columns:\n","\n","Input variables:\n","* HighBP. 0=no high BP, 1=high BP\n","* HighChol. 0=no high cholesterol, 1=high cholesterol\n","* CholCheck. Has the pateint had a cholesterol check in the last 5 years? 0=no, 1=yes\n","* BMI. Body Mass Index\n","* Smoker. Has the patient smoked at least 100 cigarettes in their entire life? [Note: 5 packs = 100 cigarettes] 0=no, 1=yes\n","* Stroke. Has the patient ever had a stroke? 0=no, 1=yes\n","* HeartDiseaseorAttack. Does the patient have coronary heart disease (CHD) or myocardial infarction (MI)? 0=no, 1=yes\n","* PhysActivity. Has the patient performed any physical activity in past 30 days, not including job? 0=no, 1=yes\n","* Fruits. Does the patient consume fruit 1 or more times per day? 0=no, 1=yes\n","* Veggies. Does the patient consume vegetables 1 or more times per day? 0=no, 1=yes\n","* HvyAlcoholConsump. Is the patient a heavy drinkerer (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week)? 0=no, 1=yes\n","* AnyHealthcare. Does the patient have any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc? 0=no, 1=yes\n","* NoDocbcCost. Was there a time in the past 12 months when the patient needed to see a doctor but could not because of cost? 0=no, 1=yes\n","* GenHlth. Would the pateint say that in general their health is: scale 1-5 1=excellent, 2=very good, 3=good, 4=fair, 5=poor\n","* MentHlth. Including stress, depression, and problems with emotions, for how many days during the past 30 days was the patient's mental health not good? scale 1-30 days\n","* PhysHlth. Inlcuding physical illness and injury, for how many days during the past 30 days was the patient's physical health not good? scale 1-30 days\n","* DiffWalk. Does the patient have serious difficulty walking or climbing stairs? 0=no, 1=yes\n","* Sex. 0=female, 1=male\n","* Age. 13-level age category (_AGEG5YR see codebook) 1=18-24, 9=60-64, 13=80 or older\n","* Education. Education level (EDUCA see codebook) scale 1-6 1=Never attended school or only kindergarten, 2=Grades 1 through 8 (Elementary), 3=Grades 9 through 11 (Some high school), 4=Grade 12 or GED (High school graduate), 5=College 1 year to 3 years (Some college or technical school), 6=College 4 years or more (College graduate)\n","* Income. Income scale (INCOME2 see codebook) scale 1-8. 1=less than \\$10,000, 5=less than \\$35,000, 8=\\$75,000 or more\n","\n","Output variable:\n","* Diabetes (0=No Risk, 1=At Risk)\n","\n","## Requirements\n","The aim of this lab is to construct a machine learning classification model that can detect whether a patient is at risk of diabetes. The model must minimize the number of false negatives.\n","\n","## Acknowledgements:\n","This dataset was released by the CDC."],"metadata":{"id":"aTH9wwpLeE5x"}},{"cell_type":"markdown","source":["The solution code for this lab is available <a href=\"https://colab.research.google.com/github/cm-int/machine-learning-fundamentals/blob/main/module_3/Labs/Lab3_2_Handling_Imbalanced_Data_Solution.ipynb\" target=\"_parent\">here</a>"],"metadata":{"id":"q3jQHF9MfqTJ"}},{"cell_type":"code","source":["# Install the imbalanced_learn library\n","\n","!pip install -U imbalanced-learn"],"metadata":{"id":"m1Xz7iB2rSL2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Upload the diabetes_data.csv file from Github\n","# This step is complete\n","\n","!wget 'https://raw.githubusercontent.com/cm-int/machine-learning-fundamentals/main/module_3/Labs/diabetes_data.csv'"],"metadata":{"id":"4y-lAtmnudl6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BHbo76D-bMqB"},"outputs":[],"source":["# Load the data and create the diabetes_data DataFrame\n","# This step is complete\n","import numpy as np\n","import pandas as pd\n","\n","diabetes_data = pd.read_csv('diabetes_data.csv')\n","diabetes_data"]},{"cell_type":"code","source":["# Remove any observations with missing data\n"],"metadata":{"id":"MUybtpvxy4EZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Examine the structure of the data using the info() method\n"],"metadata":{"id":"lHvHu0yYeoIn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Look at the statistics for the DataFrame with the describe() method\n"],"metadata":{"id":"FvG1_4Yoeu-b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract the class ('Diabetes') and calculate the amount of imbalance between the positive and naegative class labels\n","\n","has_diabetes = diabetes_data['Diabetes']\n"],"metadata":{"id":"aMmwUKbNe23M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove the class from the DataFrame\n"],"metadata":{"id":"in4eVvsBjH94"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Scale the data\n","\n","from sklearn.preprocessing import MinMaxScaler \n"],"metadata":{"id":"ZZ5t0TejfODa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the data into train and test datasets named features_train, features_test, predictions_train and predictions_test\n","\n","from sklearn.model_selection import train_test_split\n"],"metadata":{"id":"c-hAqQgYn5Ef"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Create and fit an initial model using a Random Forest"],"metadata":{"id":"RuAlLTDLpHK-"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","# Create the model. Name it forest_model\n","\n","# Make predictions with the test data and examine the confusion matrix\n"],"metadata":{"id":"arDt6qAooaTz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What do these results indicate?**\n"],"metadata":{"id":"LuMY_sQdzku-"}},{"cell_type":"code","source":["# Plot the calibration curve (create 20 bins)\n","\n","import matplotlib.pyplot as plt\n","from sklearn.calibration import calibration_curve \n"],"metadata":{"id":"BAS9IPae0sTE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the accuracy of the model \n"],"metadata":{"id":"kRticZ4eomZ6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What does the calibration curve imply for this model?**\n"],"metadata":{"id":"V5ZqtWIH0Mp2"}},{"cell_type":"code","source":["# Make predictions and calculate the G-Mean \n","\n","from imblearn.metrics import geometric_mean_score \n"],"metadata":{"id":"SgfOBCKxo5q6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the F0.5, F1, and F2 scores\n","\n","from sklearn.metrics import fbeta_score\n"],"metadata":{"id":"j2JuX3kXo9zC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the Brier score \n","\n","from sklearn.metrics import brier_score_loss \n","\n"],"metadata":{"id":"tUjFilOTpCjG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What do these metrics indicate?**\n"],"metadata":{"id":"zcvaDmiH7Gnp"}},{"cell_type":"markdown","source":["#Try sampling to balance the class labels"],"metadata":{"id":"0QEOAljRrA0S"}},{"cell_type":"code","source":["# Create and fit a BalancedRandomForestClassifier estimator\n","from imblearn.ensemble import BalancedRandomForestClassifier\n","\n","# Name the model ensemble_model\n"],"metadata":{"id":"8UMWaicrrWv8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Examine the confusion matrix\n","from sklearn.metrics import ConfusionMatrixDisplay\n"],"metadata":{"id":"fjaHv95ermW3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**How does the false positive and false negative rate of this model compare to the previous one?**\n"],"metadata":{"id":"3djC6RVG8_jE"}},{"cell_type":"code","source":["# Plot the calibration curve\n","\n","import matplotlib.pyplot as plt\n","from sklearn.calibration import calibration_curve \n"],"metadata":{"id":"sWUkd8Yf0c48"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What does this curve show?**\n"],"metadata":{"id":"_1LwLdh-9yxa"}},{"cell_type":"code","source":["# Calculate the accuracy of the model \n"],"metadata":{"id":"bKnAjLtn086n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the G-Mean \n","\n","from imblearn.metrics import geometric_mean_score \n"],"metadata":{"id":"GqakdVzT1Fhz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the F0.5, F1, and F2 scores\n","\n","from sklearn.metrics import fbeta_score\n"],"metadata":{"id":"U2ZsQ-Km1QL8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the Brier score \n","\n","from sklearn.metrics import brier_score_loss \n"],"metadata":{"id":"BTX6aLW11WKL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compare the skill level of this model to the Random Forest model\n"],"metadata":{"id":"7gs2c1s65xZd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What do these metrics tell you?**\n"],"metadata":{"id":"2CO3l8fY-CNP"}},{"cell_type":"markdown","source":["#Compare sampling to bagging"],"metadata":{"id":"RLThTHGMpRXH"}},{"cell_type":"code","source":["# Reuse the Random Forest classifier created earlier \n","from imblearn.ensemble import BalancedBaggingClassifier\n","\n","# Name the model bag_model\n"],"metadata":{"id":"Tn20dEGf2i10"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Examine the confusion matrix\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n"],"metadata":{"id":"gapEFiFC38Su"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What does this confusion matrix show?**\n"],"metadata":{"id":"pAJdSsjOAg2H"}},{"cell_type":"code","source":["# Plot the calibration curve\n","\n","import matplotlib.pyplot as plt\n","from sklearn.calibration import calibration_curve \n"],"metadata":{"id":"nGVzlk0SpQRJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the accuracy of the model \n"],"metadata":{"id":"Few3uqh_pYgD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the G-Mean \n","\n","from imblearn.metrics import geometric_mean_score \n"],"metadata":{"id":"iC7MLL73phAr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the F0.5, F1, and F2 scores\n","\n","from sklearn.metrics import fbeta_score\n"],"metadata":{"id":"nGbEbgS_qa1p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the Brier score \n","\n","from sklearn.metrics import brier_score_loss \n"],"metadata":{"id":"9e0wHfjxqmSa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compare the skill level of this model to the Random Forest model\n"],"metadata":{"id":"REbfnjgLqpZN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What do these metrics show?**\n"],"metadata":{"id":"18Ws04H8BHpT"}},{"cell_type":"markdown","source":["# Try sampling with a different classifier - the Random Undersampler with AdaBoost (RUSBoostClasifier)"],"metadata":{"id":"sQMO2fH96T_B"}},{"cell_type":"code","source":["# Again, reuse the Random Forest classifier created earlier\n","from imblearn.ensemble import RUSBoostClassifier\n","\n","# Name the model rus_model"],"metadata":{"id":"h4IpEmLJ6cNE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Examine the confusion matrix\n","from sklearn.metrics import ConfusionMatrixDisplay\n"],"metadata":{"id":"wZXcvdcV7USm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the calibration curve\n","\n","import matplotlib.pyplot as plt\n","from sklearn.calibration import calibration_curve \n"],"metadata":{"id":"EJCpPtyl80g1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What can you tell about this model?**\n"],"metadata":{"id":"V9VyD_SUHKOT"}},{"cell_type":"code","source":["# Calculate the accuracy of the model \n"],"metadata":{"id":"KkdWkp849K4x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the G-Mean \n","\n","from imblearn.metrics import geometric_mean_score \n"],"metadata":{"id":"b8R1g46W9P-c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the F0.5, F1, and F2 scores\n","\n","from sklearn.metrics import fbeta_score\n"],"metadata":{"id":"wM0Bxxvm_JHO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the Brier score \n","\n","from sklearn.metrics import brier_score_loss \n"],"metadata":{"id":"tzbVFRdZ_Obh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compare the skill level of this model to the previous models\n"],"metadata":{"id":"Jo04gM6R_UCp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What do these metrics show?**\n","\n"],"metadata":{"id":"gMSyEtsjHxi1"}},{"cell_type":"markdown","source":["# Tune the threshold for the BalancedRandomForestClassifier\n","\n","The BalancedRandomForestClassifier model had the lowest false negative rate of the models seen so far."],"metadata":{"id":"ChgZsX8x_3wo"}},{"cell_type":"code","source":["from sklearn.metrics import roc_curve\n","\n","# Find the FPR, TPR, and thresholds\n"],"metadata":{"id":"UyxPKnU8AQm3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate Youden's J Statistic\n","\n","# Find the threshold at this point. Name it optimal_threshold\n"],"metadata":{"id":"elWeiSULBF6M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Plot the curve of FPR versus TPR and highlight the threshold\n"],"metadata":{"id":"Cltp-DZJBJiN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a new predictions test set named adjusted_predictions_test.\n","# Set the predicted values to 1 for all predictions in this new test dataset with a threshold >= the optimal threshold\n","\n","# Calculate and display how many predictions have changed\n"],"metadata":{"id":"BX_1LeB6DlNd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Find the Precision, Recall, F1 Score, AUC, and Accuracy for the model when using the adjusted threshold\n","from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n"],"metadata":{"id":"n0ItHTtpAmtk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the ROC curve\n","\n","from sklearn import metrics\n"],"metadata":{"id":"eaq2yfd9OZm6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**How has this adjustment changed the false negative rate of the model?**\n"],"metadata":{"id":"zoqIK7EeKYNj"}},{"cell_type":"code","source":["# Plot the calibration curve for the predictions made using the adjusted probability threshold\n","\n","import matplotlib.pyplot as plt\n","from sklearn.calibration import calibration_curve \n","\n"],"metadata":{"id":"cHRftnrIBugi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What does this curve show?**\n"],"metadata":{"id":"UUdKtG2IKvqt"}},{"cell_type":"code","source":["# Calculate the G-Mean \n","\n","from imblearn.metrics import geometric_mean_score \n"],"metadata":{"id":"V_thF2_SC5sy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the F0.5, F1, and F2 scores\n","\n","from sklearn.metrics import fbeta_score\n"],"metadata":{"id":"wTt5MAIcE9CQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the Brier score \n","\n","from sklearn.metrics import brier_score_loss \n"],"metadata":{"id":"f68QVURdFJ_2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compare the skill level of this model to the Random Forest model\n"],"metadata":{"id":"s4A_26oZFk5T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What do these metrics show?**\n"],"metadata":{"id":"mut7H9PSNpy0"}},{"cell_type":"markdown","source":["# Try the same strategy with a different algorithm\n","\n","Bagging with Logistic Regression. This is just for comparison."],"metadata":{"id":"paTIwnsKFww-"}},{"cell_type":"code","source":["# Create and fit a Balanced Bagging classifier based on a Logistic Regression classifier with the Newton CG solver (lbfgs tends not to converge with this dataset)\n","from sklearn.linear_model import LogisticRegression\n","\n","# Name the mode lg_model\n"],"metadata":{"id":"iNx1_ydzFv5-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Examine the confusion matrix\n","from sklearn.metrics import ConfusionMatrixDisplay\n"],"metadata":{"id":"mqYpgEFkG91d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the calibration curve\n","\n","import matplotlib.pyplot as plt\n","from sklearn.calibration import calibration_curve \n"],"metadata":{"id":"nZliORQgHIHY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import roc_curve\n","\n","# Find the FPR, TPR, and thresholds for this model\n"],"metadata":{"id":"-H2ZlH2gHQ5w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate Youden's J Statistic\n","\n","# Find the threshold at this point\n"],"metadata":{"id":"aNXWNwh_Hez7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Plot the FPR versus TPR and highlight the threshold\n"],"metadata":{"id":"Yv3zwPC6HlYg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a new predictions test set named adjusted_predictions_test.\n","# Set the predicted values to 1 in this dataset for all predictions with a threshold >= the optimal threshold\n","\n","# Calculate the number of predictions that have been changed"],"metadata":{"id":"ZLWS-Z-YHtSR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Find the Precision, Recall, F1 Score, AUC, and Accuracy for the model when using the adjusted threshold\n","from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n"],"metadata":{"id":"Z7wEmqBiHzvj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What do these results show?**\n"],"metadata":{"id":"DyhHf-mGH9cM"}},{"cell_type":"markdown","source":["# Combine the original Random Forest and Logistic Regression models with a Voting Classifier\n","\n","This is for comparison with the other models. This model aims to reduce any variance that might be caused by overfitting."],"metadata":{"id":"1tQJghf3qwtA"}},{"cell_type":"code","source":["from sklearn.ensemble import VotingClassifier\n","\n","# Create an array containing the forest_model and lg_model estimators\n","\n","\n","# Create and fit a voting classifier with soft voting using the array of estimators"],"metadata":{"id":"71hDmmmrrSxr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Examine the confusion matrix\n","from sklearn.metrics import ConfusionMatrixDisplay\n"],"metadata":{"id":"SHO59T2HsTtR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the calibration curve\n","\n","import matplotlib.pyplot as plt\n","from sklearn.calibration import calibration_curve \n"],"metadata":{"id":"MJqWTbehsnRV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the G-Mean \n","\n","from imblearn.metrics import geometric_mean_score \n"],"metadata":{"id":"AZ1rK249szum"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the F0.5, F1, and F2 scores\n","\n","from sklearn.metrics import fbeta_score\n"],"metadata":{"id":"GPv-q5jCtLRG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the Brier score \n","\n","from sklearn.metrics import brier_score_loss \n"],"metadata":{"id":"Q3v8lCoGtYmf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compare the skill level of this model to the original Random Forest model\n","\n","# Generate the Brier Score for the Logistic Regression model \n","# and compare the skill level of the Voting Classifier model to the Logistic Regression model\n","\n"],"metadata":{"id":"fHrrV7Yftr63"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**How does this model compare to those that used sampling?**\n"],"metadata":{"id":"G0DWMiXZuD9x"}},{"cell_type":"markdown","source":["##If time allows\n","\n","Try creating a voting model combining classifiers for Gaussian Naive Bayes and K-Nearest Neighbors with the Random Forest model."],"metadata":{"id":"7rxBAaQm5YFK"}}]}