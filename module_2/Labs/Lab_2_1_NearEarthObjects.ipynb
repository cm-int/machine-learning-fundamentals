{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/cm-int/machine-learning-fundamentals/blob/main/module_2/Labs/Lab_2_1_NearEarthObjects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "u9_7tpMekkVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 2.1: Creating a Classification Machine Learning Model\n",
        "\n",
        "In this lab, you’ll build and test several binary classification models to classify Near Earth Objects (NEOs) as Hazardous or Not Hazardous, depending on whether they are likely to collide with the Earth.\n",
        "\n",
        "You’ll build a Decision Tree model, a Random Forest Model, and a Gradient Boosted Tree model. You’ll compare the performance of all three models, and examine the effects of adjusting the probability thresholds of predictions on the recall of a model. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VaXJHCFLkuTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**About the data:**\n",
        "\n",
        "(From https://www.kaggle.com/code/elnahas/nasa-nearest-earth-objects/data)\n",
        "\n",
        "There is an infinite number of objects in the outer space. Some of them are closer than we think. Even though we might think that a distance of 70,000 Km can not potentially harm us, but at an astronomical scale, this is a very small distance and can disrupt many natural phenomena. These objects/asteroids can thus prove to be harmful. Hence, it is wise to know what is surrounding us and what can harm us amongst those. This dataset compiles the list of NASA certified asteroids that are classified as the nearest earth object."
      ],
      "metadata": {
        "id": "QZOi1EKE19Kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The solution code for this lab is available <a href=\"https://colab.research.google.com/github/cm-int/machine-learning-fundamentals/blob/main/module_2/Labs/Lab_2_1_NearEarthObjects_solution.ipynb\" target=\"_parent\">here</a>"
      ],
      "metadata": {
        "id": "nu_Qa-w-kySS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvs-hwYPFzvo"
      },
      "source": [
        "#Read the Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the neo_v2.csv file from Github\n",
        "\n",
        "!wget 'https://raw.githubusercontent.com/cm-int/machine-learning-fundamentals/main/module_2/Labs/neo_v2.csv'"
      ],
      "metadata": {
        "id": "d6EzKobXnRtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyxSttU8F75n"
      },
      "outputs": [],
      "source": [
        "# Read the data from the neo_v2.csv file into a Pandas DataFrame named neos and display the data\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Code goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMPzAUo8KOJE"
      },
      "outputs": [],
      "source": [
        "# We want to predict whether an object is hazardous. Create a new DataFrame named hazardous containing dummy variables for the 'hazardous' column and display the results\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the two columns to 'Yes' and 'No'. The default names are 'True' and 'False' which are also the names of Python constants, and can cause problems later.\n"
      ],
      "metadata": {
        "id": "jw0wNdQ6zCZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the 'No' column from the DataFrame and flatten the result into a NumPy array\n"
      ],
      "metadata": {
        "id": "eJswavAazFUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few values from the hazardous array\n"
      ],
      "metadata": {
        "id": "HpfUFmeKzQvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlfjZis1Lxgz"
      },
      "outputs": [],
      "source": [
        "# Is 'sentry_object' useful in the neo dataframe?  How many different values does it have? (Answer: Just one - False repeated 90836 times)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Similarly, is 'orbiting_body' useful?\n"
      ],
      "metadata": {
        "id": "68iT-8Xmxkek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUHuuyrsKfRc"
      },
      "outputs": [],
      "source": [
        "# Remove the 'hazardous' column from the neos DataFrame, along with columns that probably won't help with classification (orbiting_body, sentry_object)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the Data"
      ],
      "metadata": {
        "id": "veFJUI9dam-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TSNE model and transform the data in the neos array into a 2D representation of the data\n",
        "# NOTE: This step uses a random sample of 2000 rows from the neos array, to save time\n",
        "\n",
        "# This step is complete\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_data = neos.sample(2000)\n",
        "sample_hazardous = hazardous[sample_data.index]\n",
        "\n",
        "visual_model = TSNE(learning_rate = 100, init='pca')\n",
        "visual_transformation = visual_model.fit_transform(sample_data)\n"
      ],
      "metadata": {
        "id": "cv40ouqxarIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract first and second columns from the array containing the transformed data and use them to create a Pandas DataFrame\n",
        "\n",
        "# This step is complete\n",
        "\n",
        "x_data = visual_transformation[:, 0]\n",
        "y_data = visual_transformation[:, 1]\n",
        "transformed_data = pd.DataFrame({'x':x_data, 'y':y_data})"
      ],
      "metadata": {
        "id": "fOAFxbuRbBE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the results as a Matplotlib graph\n",
        "# The clustering doesn't look promising!\n",
        "\n",
        "# This step is complete\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.scatter(transformed_data.loc[sample_hazardous==0]['x'], transformed_data.loc[sample_hazardous==0]['y'], c='red')\n",
        "plt.scatter(transformed_data.loc[sample_hazardous==1]['x'], transformed_data.loc[sample_hazardous==1]['y'], c='blue')\n",
        "plt.legend(loc ='lower left', labels = ['Not Hazardous', 'Hazardous'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dNb7jyM2bUet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try creating a 3D TSNE model\n",
        "# NOTE: This step takes between 4 and 5 minutes to run\n",
        "\n"
      ],
      "metadata": {
        "id": "eqwmM696xjcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract first, second and third columns from the array containing the transformed data and use them to create a Pandas DataFrame\n"
      ],
      "metadata": {
        "id": "tKlAlcMpxrMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the results as a 3D subplot in a Matplotlib graph\n",
        "# This time the clustering looks better, so there's a chance we can come up with a decent model\n"
      ],
      "metadata": {
        "id": "1HLgh5dVx9DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMoAQPxiK8yX"
      },
      "source": [
        "#Classification using a Decision Tree Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test datasets named features_train, features_test, predictions_train, predictions_test\n"
      ],
      "metadata": {
        "id": "ruZ7biMlpshi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Moc47aOZLAgb"
      },
      "outputs": [],
      "source": [
        "# Create and fit a Decision Tree model. Use the default values for the hyperparameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh4Ib2J9MX7N"
      },
      "outputs": [],
      "source": [
        "# Display and review the decision tree using graphviz and export_graphviz\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the model to make predictions using the features_test dataset. Save the results in an array named test_results\n"
      ],
      "metadata": {
        "id": "yfnqZIUuvH0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the first 30 test predictions to the actual test results\n",
        "\n"
      ],
      "metadata": {
        "id": "W9_YFBOHvTSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the accuracy, precision and recall of the model using K-Fold cross-validation. Set K to 5\n"
      ],
      "metadata": {
        "id": "UBKukCm4x5sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the confusion matrix for the model. How many potentially Hazardous NEOs have been misclassified as Not Hazardous (false negatives)? \n",
        "\n"
      ],
      "metadata": {
        "id": "YNBIJDL01QmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the ROC curve and calculate the AUC. Is this model better than random guesswork?\n"
      ],
      "metadata": {
        "id": "XCWtBx5k1pFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and view the probabilities generated by the decision tree model for each prediction. They are either 1 or 0\n",
        "\n",
        "test_probs = classifier_model.predict_proba(features_test)\n",
        "test_probs[0:30]"
      ],
      "metadata": {
        "id": "vwY_t0mmE-Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification using a Random Forest"
      ],
      "metadata": {
        "id": "1H_JpR142LLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and fit the model using the same training and test datasets as before\n"
      ],
      "metadata": {
        "id": "nYC7IqJw2U9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test predictions and display the results\n"
      ],
      "metadata": {
        "id": "rnbCMCjM349R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validate the model and compare the accuracy, precision, and recall against the Decision Tree model\n"
      ],
      "metadata": {
        "id": "3HdvBzrt8_WH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare Confusion Matrix and ROC curves to the decision tree model\n",
        "\n",
        "\n",
        "# Note: The number of FP and FNs have both dropped slightly. The model is still more likely to label a Hazardous NEO as Not Hazardous.\n",
        "# Is this a good thing? The default threshold of 0.5 is probably too high for this dataset, so investigate further ..."
      ],
      "metadata": {
        "id": "M604mrp5_Zte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the probabilities for each prediction in the test sample\n"
      ],
      "metadata": {
        "id": "bWXtQhj2FLML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep the probabilities for the positive outcome (Hazardous) and discard those for the negative outcome (Not Hazardous)\n"
      ],
      "metadata": {
        "id": "M3NjdE10FvHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and display the ROC curve for the model\n",
        "\n",
        "# Calculate the J statistic to find the optimal threshold for this model. Store this value in a variable named optimal_threshold.\n"
      ],
      "metadata": {
        "id": "H7nbPLn2GGbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the value of the optimal threshold for this model\n"
      ],
      "metadata": {
        "id": "a8EYuH34UtEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine how using the optimal threshold impacts the quality of the predictions made using the model \n",
        "\n",
        "# This step is complete\n",
        "\n",
        "# Find the index for every prediction with a probability probability >= optimal_threshold\n",
        "indexes = np.where(test_probs_hazardous >= optimal_threshold)\n",
        "\n",
        "# Create a new array cor holding the adjusted predictions after applying the new threshold. Initialize it with zeros, and make it the same length as the original set of test results\n",
        "adjusted_test_results = np.zeros(test_results.size)\n",
        "\n",
        "# Set the value in the adjusted predictions array to 1 for each item indicaated by the indexes array\n",
        "adjusted_test_results[indexes] = 1\n",
        "\n",
        "# Display the results\n",
        "print(adjusted_test_results)"
      ],
      "metadata": {
        "id": "2h9M7wrAs7eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a confusion matrix comparing the predictions test data and the adjusted test results\n",
        "\n",
        "# The number of false negatives should have dropped considerably, although there is now an increased level of false positives. Are false positives better than false negatives?\n"
      ],
      "metadata": {
        "id": "y9C-KMEK51P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy, precision, and recall for the model using this new threshold\n",
        "# Recall should be much improved from before. Why is this more important than precision for this model?\n",
        "\n",
        "# This step is complete\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "accuracy = accuracy_score(predictions_test, adjusted_test_results)\n",
        "precision = precision_score(predictions_test, adjusted_test_results)\n",
        "recall = recall_score(predictions_test, adjusted_test_results)\n",
        "\n",
        "print(f'Accuracy: {accuracy}\\n')\n",
        "print(f'Precision: {precision}\\n')\n",
        "print(f'Recall: {recall}\\n')"
      ],
      "metadata": {
        "id": "A8dR1aFgLEaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classification using Gradient Boosted Decision Tree"
      ],
      "metadata": {
        "id": "DMxSIm_UP_WX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and fit a Gradient Boosted decision tree model. Set n_estimators to 100, learning_rate to 0.1, and max_depth to 3\n"
      ],
      "metadata": {
        "id": "ZUYCSh3SQYGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test predictions and display the results\n"
      ],
      "metadata": {
        "id": "-7ZgmH31RAJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform cross-validation, and calculate the accuracy, precision and recall of the model\n"
      ],
      "metadata": {
        "id": "vtcCD5RMRNpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the Confusion Matrix and ROC curves\n",
        "\n",
        "# This model has even more FNs than the original Random Forest, but far fewer FPs"
      ],
      "metadata": {
        "id": "CgfEJkoHR8j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the ROC curve and calculate the optimal threshold for this model, as per the Random Forest model\n"
      ],
      "metadata": {
        "id": "Jwo1FUFHUAxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the value of the optimal threshold for this model"
      ],
      "metadata": {
        "id": "MMooTsG8Unx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Follow the same process as before to see how amendning the threshold affects the quality of the model\n",
        "\n",
        "# Find the index for every prediction with a probability probability >= optimal_threshold\n",
        "\n",
        "\n",
        "# Create a new array cor holding the adjusted predictions after applying the new threshold. Initialize it with zeros, and make it the same length as the original set of test results\n",
        "\n",
        "# Set the value in the adjusted predictions array to 1 for each item indicaated by the indexes array\n",
        "\n",
        "# Display the results\n"
      ],
      "metadata": {
        "id": "_TvnMRMtVkpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy, precision, and recall for the model using this new threshold\n",
        "# Again, recall should be much improved from before.\n",
        "\n"
      ],
      "metadata": {
        "id": "cJqsm0ZVV-i3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
